I201223 09:44:54.071138 1 util/log/sync_buffer.go:195 ⋮ [config] file created at: 2020/12/23 09:44:54
I201223 09:44:54.071143 1 util/log/sync_buffer.go:195 ⋮ [config] running on machine: ‹roach1›
I201223 09:44:54.071147 1 util/log/sync_buffer.go:195 ⋮ [config] binary: CockroachDB CCL v20.2.3 (x86_64-unknown-linux-gnu, built 2020/12/14 18:33:39, go1.13.14)
I201223 09:44:54.071151 1 util/log/sync_buffer.go:195 ⋮ [config] arguments: ‹[/cockroach/cockroach start --insecure --join=roach1,roach2,roach3]›
I201223 09:44:54.071156 1 util/log/sync_buffer.go:195 ⋮ [config] line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
W201223 09:44:54.071087 1 cli/start.go:1139 ⋮ ALL SECURITY CONTROLS HAVE BEEN DISABLED!

This mode is intended for non-production testing only.

In this mode:
- Your cluster is open to any client that can access ‹any of your IP addresses›.
- Intruders with access to your machine or network can observe client-server traffic.
- Intruders can log in without password and read or write any data in the cluster.
- Intruders can consume all your server's resources and cause unavailability.
I201223 09:44:54.071212 1 cli/start.go:1149 ⋮ To start a secure server without mandating TLS for clients,
consider --accept-sql-without-tls instead. For other options, see:

- ‹https://go.crdb.dev/issue-v/53404/v20.2›
- https://www.cockroachlabs.com/docs/v20.2/secure-a-cluster.html
I201223 09:44:54.071417 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 31 GiB instead:›
W201223 09:44:54.071432 1 cli/start.go:983 ⋮ ‹Using the default setting for --cache (128 MiB).›
‹  A significantly larger value is usually needed for good performance.›
‹  If you have a dedicated server a reasonable setting is --cache=.25 (7.8 GiB).›
I201223 09:44:54.071571 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 31 GiB instead:›
I201223 09:44:54.071579 1 cli/start.go:1164 ⋮ ‹CockroachDB CCL v20.2.3 (x86_64-unknown-linux-gnu, built 2020/12/14 18:33:39, go1.13.14)›
I201223 09:44:54.072084 1 server/status/recorder.go:605 ⋮ ‹available memory from cgroups (8.0 EiB) is unsupported, using system memory 31 GiB instead:›
I201223 09:44:54.072093 1 server/config.go:434 ⋮ system total memory: ‹31 GiB›
I201223 09:44:54.072103 1 server/config.go:436 ⋮ server configuration:
‹max offset             500000000›
‹cache size             128 MiB›
‹SQL memory pool size   7.8 GiB›
‹scan interval          10m0s›
‹scan min idle time     10ms›
‹scan max idle time     1s›
‹event log enabled      true›
I201223 09:44:54.072135 1 cli/start.go:961 ⋮ using local environment variables: ‹COCKROACH_CHANNEL=official-docker›
I201223 09:44:54.072144 1 cli/start.go:968 ⋮ process identity: ‹uid 0 euid 0 gid 0 egid 0›
I201223 09:44:54.073918 1 cli/start.go:504 ⋮ GEOS loaded from directory ‹/usr/local/lib/cockroach›
I201223 09:44:54.073937 1 cli/start.go:509 ⋮ starting cockroach node
I201223 09:44:54.083853 73 server/server.go:782 ⋮ [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I201223 09:44:54.107240 73 server/config.go:625 ⋮ [n?] 1 storage engine‹› initialized
I201223 09:44:54.107259 73 server/config.go:628 ⋮ [n?] ‹Pebble cache size: 128 MiB›
I201223 09:44:54.107266 73 server/config.go:628 ⋮ [n?] ‹store 0: RocksDB, max size 0 B, max open file limit 1043576›
W201223 09:44:54.108815 73 cli/start.go:907 ⋮ neither --listen-addr nor --advertise-addr was specified.
The server will advertise ‹"roach1"› to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I201223 09:44:54.108947 45 server/server.go:1416 ⋮ [n?] connecting to gossip network to verify cluster ID ‹"a80c75e2-16e2-4e50-a3ad-eaec13a9821b"›
W201223 09:44:54.110617 73 gossip/gossip.go:1494 ⋮ [n?] no incoming or outgoing connections
I201223 09:44:54.110652 73 gossip/gossip.go:403 ⋮ [n1] NodeDescriptor set to ‹node_id:1 address:<network_field:"tcp" address_field:"roach1:26257" > attrs:<> locality:<> ServerVersion:<major_val:20 minor_val:2 patch:0 unstable:0 > build_tag:"v20.2.3" started_at:1608716694110646940 cluster_name:"" sql_address:<network_field:"tcp" address_field:"roach1:26257" >›
W201223 09:44:54.325063 47 gossip/gossip.go:1277 ⋮ [n1] invalid bootstrap address: ‹&{typ:tcp addr:roach2:26257}›, ‹lookup roach2 on 127.0.0.11:53: no such host›
W201223 09:44:54.536542 47 gossip/gossip.go:1277 ⋮ [n1] invalid bootstrap address: ‹&{typ:tcp addr:roach3:26257}›, ‹lookup roach3 on 127.0.0.11:53: no such host›
W201223 09:44:54.538841 220 kv/kvserver/replica_range_lease.go:555 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] can't determine lease status of (n1,s1):1 due to node liveness error: node not in the liveness table
(1) attached stack trace
  -- stack trace:
  | github.com/cockroachdb/cockroach/pkg/kv/kvserver.init
  | 	/go/src/github.com/cockroachdb/cockroach/pkg/kv/kvserver/node_liveness.go:45
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5228
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.doInit
  | 	/usr/local/go/src/runtime/proc.go:5223
  | runtime.main
  | 	/usr/local/go/src/runtime/proc.go:190
  | runtime.goexit
  | 	/usr/local/go/src/runtime/asm_amd64.s:1357
Wraps: (2) node not in the liveness table
Error types: (1) *withstack.withStack (2) *errutil.leafError
I201223 09:44:54.538966 45 server/server.go:1419 ⋮ [n1] node connected via gossip
W201223 09:44:54.538943 220 kv/kvserver/store.go:1704 ⋮ [n1,s1,r6/1:‹/Table/{SystemCon…-11}›] could not gossip system config: ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
(1) ‹[NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown›
Error types: (1) *roachpb.NotLeaseHolderError
I201223 09:44:54.539196 73 server/node.go:430 ⋮ [n1] initialized store [n1,s1]: disk (capacity=194 GiB, available=163 GiB, used=1.9 MiB, logicalBytes=19 MiB), ranges=36, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=3174.00 p90=17806.00 pMax=20057049.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I201223 09:44:54.539265 73 kv/kvserver/stores.go:236 ⋮ [n1] read 0 node addresses from persistent storage
I201223 09:44:54.541187 73 server/node.go:489 ⋮ [n1] started with engine type ‹2›
I201223 09:44:54.541221 73 server/node.go:491 ⋮ [n1] started with attributes ‹[]›
I201223 09:44:54.541257 73 server/goroutinedumper/goroutinedumper.go:120 ⋮ [n1] writing goroutine dumps to ‹/cockroach/cockroach-data/logs/goroutine_dump›
I201223 09:44:54.541271 73 server/heapprofiler/heapprofiler.go:49 ⋮ [n1] writing go heap profiles to ‹/cockroach/cockroach-data/logs/heap_profiler› at least every 1h0m0s
I201223 09:44:54.541283 73 server/heapprofiler/cgoprofiler.go:53 ⋮ [n1] to enable jmalloc profiling: "export MALLOC_CONF=prof:true" or "ln -s prof:true /etc/malloc.conf"
I201223 09:44:54.541290 73 server/heapprofiler/statsprofiler.go:54 ⋮ [n1] writing memory stats to ‹/cockroach/cockroach-data/logs/heap_profiler› at last every 1h0m0s
I201223 09:44:54.541301 73 server/server.go:1536 ⋮ [n1] starting http server at ‹[::]:8080› (use: ‹roach1:8080›)
I201223 09:44:54.541316 73 server/server.go:1543 ⋮ [n1] starting grpc/postgres server at ‹[::]:26257›
I201223 09:44:54.541328 73 server/server.go:1544 ⋮ [n1] advertising CockroachDB node at ‹roach1:26257›
I201223 09:44:54.552211 73 sql/sqlliveness/slinstance/slinstance.go:252 ⋮ [n1] starting SQL liveness instance
I201223 09:44:54.552306 288 sql/temporary_schema.go:497 ⋮ [n1] running temporary object cleanup background job
I201223 09:44:54.552409 73 server/server_sql.go:753 ⋮ [n1] done ensuring all necessary migrations have run
I201223 09:44:54.552426 73 server/server.go:1876 ⋮ [n1] serving sql connections
I201223 09:44:54.552538 73 cli/start.go:670 ⋮ [config] clusterID: ‹a80c75e2-16e2-4e50-a3ad-eaec13a9821b›
I201223 09:44:54.552571 73 cli/start.go:680 ⋮ node startup completed:
CockroachDB node starting at 2020-12-23 09:44:54.552474223 +0000 UTC (took 0.5s)
build:               CCL v20.2.3 @ 2020/12/14 18:33:39 (go1.13.14)
webui:               ‹http://roach1:8080›
sql:                 ‹postgresql://root@roach1:26257?sslmode=disable›
RPC client flags:    ‹/cockroach/cockroach <client cmd> --host=roach1:26257 --insecure›
logs:                ‹/cockroach/cockroach-data/logs›
temp dir:            ‹/cockroach/cockroach-data/cockroach-temp867977027›
external I/O path:   ‹/cockroach/cockroach-data/extern›
store[0]:            ‹path=/cockroach/cockroach-data›
storage engine:      pebble
status:              restarted pre-existing node
clusterID:           ‹a80c75e2-16e2-4e50-a3ad-eaec13a9821b›
nodeID:              1
I201223 09:44:54.552810 302 jobs/job_scheduler.go:346 ⋮ [n1] waiting 4m0s before scheduled jobs daemon start
I201223 09:44:54.560039 288 sql/temporary_schema.go:532 ⋮ [n1] found 0 temporary schemas
I201223 09:44:54.560072 288 sql/temporary_schema.go:535 ⋮ [n1] early exiting temporary schema cleaner as no temporary schemas were found
I201223 09:44:54.560086 288 sql/temporary_schema.go:536 ⋮ [n1] completed temporary object cleanup job
I201223 09:44:54.560097 288 sql/temporary_schema.go:614 ⋮ [n1] temporary object cleaner next scheduled to run at 2020-12-23 10:14:54.552269558 +0000 UTC
I201223 09:44:54.561766 303 server/server_update.go:55 ⋮ [n1] no need to upgrade, cluster already at the newest version
I201223 09:44:54.567357 286 sql/sqlliveness/slstorage/slstorage.go:342 ⋮ [n1] inserted sqlliveness session ‹29c2036376bc4c55a8c59aac22991d35›
I201223 09:44:54.567392 286 sql/sqlliveness/slinstance/slinstance.go:143 ⋮ [n1] created new SQL liveness session ‹29c2036376bc4c55a8c59aac22991d35›
I201223 09:44:54.575484 284 sql/event_log.go:162 ⋮ [n1] Event: ‹"node_restart"›, target: 1, info: ‹{Descriptor:{NodeID:1 Address:roach1:26257 Attrs: Locality: ServerVersion:20.2 BuildTag:v20.2.3 StartedAt:1608716694110646940 LocalityAddress:[] ClusterName: SQLAddress:roach1:26257} ClusterID:a80c75e2-16e2-4e50-a3ad-eaec13a9821b StartedAt:1608716694110646940 LastUp:1608716499906703326}›
I201223 09:44:55.938041 47 gossip/gossip.go:1508 ⋮ [n1] node has connected to cluster via gossip
I201223 09:44:55.939184 47 kv/kvserver/stores.go:255 ⋮ [n1] wrote 0 node addresses to persistent storage
I201223 09:45:04.541851 59 server/status/runtime.go:522 ⋮ [n1] runtime stats: 176 MiB RSS, 192 goroutines, 17 MiB/40 MiB/42 MiB GO alloc/idle/total, 14 MiB/20 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (12x), 13 KiB/4.4 KiB (r/w)net
I201223 09:45:11.851768 1 cli/start.go:733 ⋮ received signal 'terminated'
I201223 09:45:11.852470 1 cli/start.go:817 ⋮ initiating graceful shutdown of server
I201223 09:45:11.856012 707 server/drain.go:175 ⋮ [server drain process] drain remaining: 1
I201223 09:45:11.856649 707 server/drain.go:177 ⋮ [server drain process] drain details: liveness record: 1
I201223 09:45:12.062569 707 server/drain.go:175 ⋮ [server drain process] drain remaining: 0
I201223 09:45:12.063499 707 util/stop/stopper.go:563 ⋮ [server drain process] quiescing
W201223 09:45:12.064462 286 sql/sqlliveness/slinstance/slinstance.go:182 ⋮ [n1] exiting heartbeat loop
W201223 09:45:12.064564 297 jobs/registry.go:672 ⋮ canceling all adopted jobs due to stopper quiescing
I201223 09:45:12.069943 1 cli/start.go:869 ⋮ server drained and shutdown completed
